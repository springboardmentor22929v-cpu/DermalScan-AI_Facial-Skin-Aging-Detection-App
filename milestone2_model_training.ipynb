{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319acc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Global constants (matching Milestone 1)\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Project paths\n",
    "DATASET_PATH = \"DATASET\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "MODEL_DIR = os.path.join(OUTPUT_DIR, \"models\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [OUTPUT_DIR, MODEL_DIR]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\" Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Create generators\n",
    "print(\"Creating training generator...\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"\\nCreating validation generator...\")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_generator.class_indices)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(\"Class mapping:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb400111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model with pretrained weights\n",
    "base_model = EfficientNetB0(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks\n",
    "checkpoint_path = os.path.join(MODEL_DIR, 'base_model_checkpoint.h5')\n",
    "csv_path = os.path.join(OUTPUT_DIR, 'training_history.csv')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    CSVLogger(csv_path)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 15\n",
    "print(\"Training base model...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"\\n Base model training complete\")\n",
    "\n",
    "# Save the trained model\n",
    "base_model_path = os.path.join(MODEL_DIR, 'base_model.h5')\n",
    "model.save(base_model_path)\n",
    "print(f\"Model saved to {base_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "history_plot_path = os.path.join(OUTPUT_DIR, 'training_history.png')\n",
    "plt.savefig(history_plot_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Training history plot saved to {history_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dd255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze first half of the base model layers\n",
    "num_layers = len(base_model.layers)\n",
    "freeze_until = num_layers // 2\n",
    "for layer in base_model.layers[:freeze_until]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display updated model\n",
    "model.summary()\n",
    "\n",
    "# Set up callbacks for fine-tuning\n",
    "fine_tune_checkpoint = os.path.join(MODEL_DIR, 'fine_tuned_checkpoint.h5')\n",
    "fine_tune_csv = os.path.join(OUTPUT_DIR, 'fine_tuning_history.csv')\n",
    "\n",
    "fine_tune_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        fine_tune_checkpoint,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    CSVLogger(fine_tune_csv)\n",
    "]\n",
    "\n",
    "# Fine-tune the model\n",
    "print(\"\\nFine-tuning the model...\")\n",
    "EPOCHS_FINE_TUNE = 10\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    callbacks=fine_tune_callbacks\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "fine_tuned_model_path = os.path.join(MODEL_DIR, 'fine_tuned_model.h5')\n",
    "model.save(fine_tuned_model_path)\n",
    "print(f\"\\n Fine-tuned model saved to {fine_tuned_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "print(\"Evaluating final model...\")\n",
    "final_loss, final_accuracy = model.evaluate(\n",
    "    validation_generator,\n",
    "    steps=validation_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Validation Loss: {final_loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Generate predictions for confusion matrix\n",
    "validation_generator.reset()\n",
    "predictions = model.predict(\n",
    "    validation_generator,\n",
    "    steps=validation_generator.samples // BATCH_SIZE\n",
    ")\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = validation_generator.classes[:len(predicted_classes)]\n",
    "\n",
    "# Generate classification report\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "report = classification_report(\n",
    "    true_classes,\n",
    "    predicted_classes,\n",
    "    target_names=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Save classification report\n",
    "report_path = os.path.join(OUTPUT_DIR, 'classification_report.json')\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "\n",
    "# Create confusion matrix plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save confusion matrix plot\n",
    "cm_path = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\n",
    "plt.savefig(cm_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Evaluation metrics saved to {OUTPUT_DIR}\")\n",
    "print(f\"Classification report: {report_path}\")\n",
    "print(f\"Confusion matrix: {cm_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_confidence(image_path, model, class_labels):\n",
    "    \"\"\"\n",
    "    Predict skin condition with confidence scores\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Get confidence scores for each class\n",
    "    results = {}\n",
    "    for i, score in enumerate(predictions[0]):\n",
    "        class_name = class_labels[i]\n",
    "        confidence = float(score * 100)\n",
    "        results[class_name] = confidence\n",
    "        \n",
    "    return results\n",
    "\n",
    "def analyze_facial_aging(image_path, model, class_labels):\n",
    "    \"\"\"\n",
    "    Analyze facial aging signs in an image and return predictions with confidence scores\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Could not load image\")\n",
    "    \n",
    "    # Convert to RGB for visualization\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load the face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Detect faces\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        # If no faces detected, analyze the whole image\n",
    "        img_resized = cv2.resize(img, IMG_SIZE)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        predictions = model.predict(img_array)\n",
    "        \n",
    "        # Create a result for the whole image\n",
    "        results = [{\n",
    "            'bbox': (0, 0, img.shape[1], img.shape[0]),\n",
    "            'predictions': {\n",
    "                class_labels[i]: float(score * 100)\n",
    "                for i, score in enumerate(predictions[0])\n",
    "            }\n",
    "        }]\n",
    "        return img_rgb, results\n",
    "    \n",
    "    results = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face ROI\n",
    "        face_roi = img[y:y+h, x:x+w]\n",
    "        \n",
    "        # Preprocess ROI for model\n",
    "        face_roi = cv2.resize(face_roi, IMG_SIZE)\n",
    "        face_array = tf.keras.preprocessing.image.img_to_array(face_roi)\n",
    "        face_array = np.expand_dims(face_array, axis=0)\n",
    "        face_array = preprocess_input(face_array)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(face_array)\n",
    "        \n",
    "        # Get confidence scores\n",
    "        face_results = {\n",
    "            'bbox': (x, y, w, h),\n",
    "            'predictions': {}\n",
    "        }\n",
    "        \n",
    "        for i, score in enumerate(predictions[0]):\n",
    "            class_name = class_labels[i]\n",
    "            confidence = float(score * 100)\n",
    "            face_results['predictions'][class_name] = confidence\n",
    "            \n",
    "        results.append(face_results)\n",
    "    \n",
    "    return img_rgb, results\n",
    "\n",
    "def visualize_predictions(image, results):\n",
    "    \"\"\"\n",
    "    Visualize the predictions with bounding boxes and labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    for result in results:\n",
    "        x, y, w, h = result['bbox']\n",
    "        predictions = result['predictions']\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rect = plt.Rectangle((x, y), w, h, fill=False, color='red', linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        # Format prediction text\n",
    "        text = []\n",
    "        for class_name, confidence in predictions.items():\n",
    "            text.append(f\"{class_name}: {confidence:.1f}%\")\n",
    "        \n",
    "        # Add text above bounding box\n",
    "        plt.text(x, y-10, '\\n'.join(text), \n",
    "                bbox=dict(facecolor='white', alpha=0.7),\n",
    "                fontsize=8, color='black')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('Facial Aging Analysis')\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image path\n",
    "test_image_path = \"test1.jpg\"\n",
    "print(f\"\\nAnalyzing {os.path.basename(test_image_path)}...\")\n",
    "\n",
    "try:\n",
    "    # Analyze image\n",
    "    image, results = analyze_facial_aging(test_image_path, model, class_names)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt = visualize_predictions(image, results)\n",
    "    \n",
    "    # Save the visualization\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"prediction_{os.path.basename(test_image_path)}\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nFace #{i}:\")\n",
    "        for class_name, confidence in result['predictions'].items():\n",
    "            print(f\"{class_name}: {confidence:.1f}%\")\n",
    "            \n",
    "    print(f\" Saved visualization to {output_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
